{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a9889de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# python 3.10.9에서 작성 되었습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c337c112",
   "metadata": {},
   "source": [
    "konlpy 사용시 참고 링크에 들어가서 설치하세요\n",
    "\n",
    "참고 : https://wikidocs.net/22488"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f6f6a9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# pip install kss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a84741",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# pip install konlpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc9dd174",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c62864",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 패키지 불러오기\n",
    "import kss\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow\n",
    "import re\n",
    "from statannot import add_stat_annotation\n",
    "from nltk.tag import pos_tag\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "from konlpy.tag import Hannanum\n",
    "from konlpy.tag import Okt\n",
    "from konlpy.tag import Kkma\n",
    "from wordcloud import WordCloud\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "hannanum = Hannanum()\n",
    "kkma = Kkma()\n",
    "okt = Okt()\n",
    "tfidf = TfidfVectorizer()\n",
    "tokenizer = Tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5458d4db",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('OKT 형태소 분석 :',okt.morphs(\"열심히 코딩한 당신, 연휴에는 여행을 가봐요\"))\n",
    "print('OKT 품사 태깅 :',okt.pos(\"열심히 코딩한 당신, 연휴에는 여행을 가봐요\"))\n",
    "print('OKT 명사 추출 :',okt.nouns(\"열심히 코딩한 당신, 연휴에는 여행을 가봐요\")) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9267dab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 로우 데이터 불러오기 = df\n",
    "df = pd.read_excel('dataframe.xlsx', index_col = 0)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c2b7d0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 컬럼명 변경\n",
    "df.columns = ['제목', '연수명', '분류', '만족도', '내용']\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95736c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결측치 확인 True가 있으면 nan값 있음\n",
    "df['내용'].isna().unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f1cecd8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tfidf.fit(df['내용'])\n",
    "tfidf.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d85fdf64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# label : 1 = 만족도 5, 4 \n",
    "# label : 0 = 만족도 3, 2, 1\n",
    "df['label'] = df['만족도'] >= 4\n",
    "df['label'] = df['label'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30db3d65",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 만족도 5, 4 = df1\n",
    "df1 = df[df['만족도'].isin([5, 4])]\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a7be77a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 만족도 3, 2, 1 = df2\n",
    "df2 = df[df['만족도'].isin([3, 2, 1])]\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6daf365",
   "metadata": {},
   "outputs": [],
   "source": [
    "#전처리 함수 만들기\n",
    "def preprocessing(review, okt, remove_stopwords = False, stop_words =[]):\n",
    "    #함수인자설명\n",
    "    # review: 전처리할 텍스트\n",
    "    # okt: okt객체를 반복적으로 생성하지 않고 미리 생성 후 인자로 받음\\\n",
    "    # remove_stopword: 불용어를 제거할지 여부 선택. 기본값 False\n",
    "    # stop_words: 불용어 사전은 사용자가 직접 입력, 기본값 빈 리스트\n",
    "\n",
    "    # 1. 한글 및 공백 제외한 문자 모두 제거\n",
    "    review_text = re.sub('[^가-힣ㄱ-ㅎㅏ-ㅣ\\\\s]','',review)\n",
    "\n",
    "    #2. okt 객체를 활용하여 형태소 단어로 나눔\n",
    "    word_review = okt.morphs(review_text,stem=True)\n",
    "\n",
    "    if remove_stopwords:\n",
    "        #3. 불용어 제거\n",
    "        word_review = [token for token in word_review if not token in stop_words]\n",
    "    return word_review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa304f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 불용어 제거 = https://www.ranks.nl/stopwords/korean\n",
    "f = open(\"Korean Stopwords.txt\", \"r\", encoding='UTF8')\n",
    "\n",
    "lst = []\n",
    "while True:\n",
    "    line = f.readline().strip()\n",
    "    if not line: break\n",
    "    lst.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e897c225",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 줄바꿈 제거 추가\n",
    "lst2 = ['\\n', '\\n\\n', '\\n\\n\\n', '\\n\\n\\n\\n', '\\n\\n\\n\\n\\n']\n",
    "lst.extend(lst2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce025304",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 로우 데이터 = df 전처리\n",
    "stop_words = lst\n",
    "clean_review_df = []\n",
    "\n",
    "for review in df['내용']:\n",
    "    # 리뷰가 문자열인 경우만 전처리 진행\n",
    "    if type(review) == str:\n",
    "        clean_review_df.append(preprocessing(review,okt, remove_stopwords = True, stop_words = stop_words))\n",
    "    else:\n",
    "        clean_review_df.append([]) #str이 아닌 행은 빈칸으로 놔두기\n",
    "clean_review_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "916db2cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 만족도 5, 4 = df1 전처리\n",
    "stop_words = lst\n",
    "clean_review_df1 = []\n",
    "\n",
    "for review in df1['내용']:\n",
    "    # 리뷰가 문자열인 경우만 전처리 진행\n",
    "    if type(review) == str:\n",
    "        clean_review_df1.append(preprocessing(review,okt, remove_stopwords = True, stop_words = stop_words))\n",
    "    else:\n",
    "        clean_review_df1.append([]) #str이 아닌 행은 빈칸으로 놔두기\n",
    "clean_review_df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "173bd4af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 만족도 3, 2, 1 = df2 전처리\n",
    "stop_words = lst\n",
    "clean_review_df2 = []\n",
    "\n",
    "for review in df2['내용']:\n",
    "    # 리뷰가 문자열인 경우만 전처리 진행\n",
    "    if type(review) == str:\n",
    "        clean_review_df2.append(preprocessing(review,okt, remove_stopwords = True, stop_words = stop_words))\n",
    "    else:\n",
    "        clean_review_df2.append([]) #str이 아닌 행은 빈칸으로 놔두기\n",
    "clean_review_df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00929788",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 로우 데이터 불러오기 = df \n",
    "sequences = tokenizer.texts_to_sequences(clean_review_df)\n",
    "\n",
    "word_vocab = tokenizer.word_index #단어사전형태\n",
    "MAX_SEQUENCE_LENGTH = 8 #문장 최대 길이\n",
    "\n",
    "#데이터\n",
    "df_inputs = pad_sequences(sequences,maxlen=MAX_SEQUENCE_LENGTH,padding='post')\n",
    "\n",
    "#데이터 라벨 벡터화\n",
    "df_labels = np.array(df['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8888fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b39e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3434dbab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
