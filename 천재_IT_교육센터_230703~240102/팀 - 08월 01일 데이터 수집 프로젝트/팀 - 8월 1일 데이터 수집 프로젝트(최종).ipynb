{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62189169",
   "metadata": {},
   "outputs": [],
   "source": [
    "# python 3.10.9에서 작성 되었습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c337c112",
   "metadata": {},
   "source": [
    "konlpy 사용시 참고 링크에 들어가서 설치하세요\n",
    "\n",
    "참고 : https://wikidocs.net/22488"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c62864",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 패키지 불러오기\n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "import json\n",
    "from konlpy.tag import Okt\n",
    "from wordcloud import WordCloud\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "okt = Okt()\n",
    "tokenizer = Tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc3d355",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트\n",
    "print('OKT 형태소 분석 :',okt.morphs(\"열심히 코딩한 당신, 연휴에는 여행을 가봐요\"))\n",
    "print('OKT 품사 태깅 :',okt.pos(\"열심히 코딩한 당신, 연휴에는 여행을 가봐요\"))\n",
    "print('OKT 명사 추출 :',okt.nouns(\"열심히 코딩한 당신, 연휴에는 여행을 가봐요\")) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9267dab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 로우 데이터 불러오기 = df\n",
    "df = pd.read_excel('dataframe.xlsx')\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c2b7d0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 컬럼명 변경\n",
    "df.columns = ['제목', '연수명', '분류', '만족도', '내용']\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a421ba3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# label에 기본값으로 3\n",
    "df['label'] = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60828cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 만족도 2이하면 0, 만족도 4이상이면 1\n",
    "for i in range(len(df)):\n",
    "    if df['만족도'][i]<=2:\n",
    "        df['label'][i] = 0\n",
    "    elif df['만족도'][i] >= 4:\n",
    "        df['label'][i] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba3244b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# label이 3이 아닌것만\n",
    "df = df[df['label'] != 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf7d63b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# index 초기화\n",
    "df = df.reset_index(drop=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "893ed9e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 만족도 5, 4 = df1\n",
    "df1 = df[df['만족도'].isin([5, 4])]\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb35a054",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 만족도 2, 1 = df2\n",
    "df2 = df[df['만족도'].isin([2, 1])]\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeeefb61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 내용만 추출\n",
    "reviews = df['내용']\n",
    "reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "985c9202",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mecab 작동 시험\n",
    "from konlpy.tag import Mecab \n",
    "mecab_tokenizer = Mecab(dicpath=r\"C:\\mecab\\share\\mecab-ko-dic\").morphs\n",
    "print('mecab check :', mecab_tokenizer('어릴때보고 지금다시봐도 재밌어요ㅋㅋ'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9606098",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결측치 확인 True가 있으면 nan값 있음\n",
    "reviews.isna().unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a385ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#결측치 제거\n",
    "reviews = reviews.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f23cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mecab으로 토큰화\n",
    "from konlpy.tag import Mecab\n",
    "\n",
    "tokens = [mecab_tokenizer(word) for word in reviews]\n",
    "\n",
    "tokens = list(map(lambda x : \" \".join(x), tokens))\n",
    "\n",
    "tokens[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da8a27f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 감성 사전 가져오기\n",
    "with open('SentiWord_info.json', encoding='utf-8-sig', mode='r') as f: \n",
    "    SentiWord_info = json.load(f)\n",
    "\n",
    "sentiword_dic = pd.DataFrame(SentiWord_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99014234",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 감성사전으로 점수화\n",
    "\n",
    "df3 = pd.DataFrame(columns=(\"review\", \"sentiment\"))  # 리뷰별 극성을 저장하기 위한 데이터프레임 생성\n",
    "idx = 0                                             # 다음 리뷰로 넘기기 위한 초기값\n",
    " \n",
    "for token in tokens:                                # 전체 리뷰에서 문장 하나씩 가져옴 \n",
    "    sentiment = 0                                   # 초기 감성값 0으로 설정\n",
    "    print(idx)\n",
    "    for i in range(0, len(sentiword_dic)):            # 감성사전의 모든 단어를 하나씩 선택\n",
    "        if sentiword_dic.word[i] in token:              # 리뷰 문장에 감성 단어가 있는지 확인\n",
    "            sentiment += int(sentiword_dic.polarity[i])   # 감성단어가 있다면 극성값 합계를 구함.\n",
    "    df3.loc[idx] = [token, sentiment]                  # 리뷰별 극성값을 데이터프레임으로 쌓음\n",
    "    idx += 1                                          # 다름 리뷰 문장으로 넘어감"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1257606",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예측라벨 컬럼 생성\n",
    "df3['pre_label'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50cafb91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentiment가 음수,0면 0, 양수면 1\n",
    "for i in range(len(df3)):\n",
    "    if df3['sentiment'][i]<0:\n",
    "        df3['pre_label'][i] = 0\n",
    "    else:\n",
    "        df3['pre_label'][i] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eacf4e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5fb4ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3[df3['pre_label'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d9f251",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 분류 평가\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score, precision_score , recall_score, f1_score, roc_auc_score\n",
    "\n",
    "print(confusion_matrix(df['label'], df3['pre_label']))\n",
    "print(\"정확도:\", accuracy_score(df['label'], df3['pre_label']))\n",
    "print(\"정밀도:\", precision_score(df['label'], df3['pre_label']))\n",
    "print(\"재현율(민감도):\", recall_score(df['label'], df3['pre_label']))\n",
    "print(\"f1-score:\", f1_score(df['label'], df3['pre_label']))\n",
    "print(\"roc_auc_score:\", roc_auc_score(df['label'], df3['pre_label']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ce2df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파일로 내보내기\n",
    "df3.to_excel('./df10.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ebcb1aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d46772c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2ba0964d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6daf365",
   "metadata": {},
   "outputs": [],
   "source": [
    "#전처리 함수 만들기\n",
    "def preprocessing(review, okt, remove_stopwords = False, stop_words =[]):\n",
    "    #함수인자설명\n",
    "    # review: 전처리할 텍스트\n",
    "    # okt: okt객체를 반복적으로 생성하지 않고 미리 생성 후 인자로 받음\\\n",
    "    # remove_stopword: 불용어를 제거할지 여부 선택. 기본값 False\n",
    "    # stop_words: 불용어 사전은 사용자가 직접 입력, 기본값 빈 리스트\n",
    "\n",
    "    # 1. 한글 및 공백 제외한 문자 모두 제거\n",
    "    review_text = re.sub('[^가-힣ㄱ-ㅎㅏ-ㅣ\\\\s]','',review)\n",
    "\n",
    "    #2. okt 객체를 활용하여 형태소 단어로 나눔\n",
    "    word_review = okt.morphs(review_text,stem=True)\n",
    "\n",
    "    if remove_stopwords:\n",
    "        #3. 불용어 제거\n",
    "        word_review = [token for token in word_review if not token in stop_words]\n",
    "    return word_review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa304f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 불용어 제거 = https://www.ranks.nl/stopwords/korean\n",
    "f = open(\"Korean Stopwords.txt\", \"r\", encoding='UTF8')\n",
    "\n",
    "lst = []\n",
    "while True:\n",
    "    line = f.readline().strip()\n",
    "    if not line: break\n",
    "    lst.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e897c225",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 줄바꿈 제거 추가\n",
    "lst2 = ['\\n', '\\n\\n', '\\n\\n\\n', '\\n\\n\\n\\n', '\\n\\n\\n\\n\\n']\n",
    "lst.extend(lst2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce025304",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 로우 데이터 = df 전처리\n",
    "stop_words = lst\n",
    "clean_review_df = []\n",
    "\n",
    "for review in df['내용']:\n",
    "    # 리뷰가 문자열인 경우만 전처리 진행\n",
    "    if type(review) == str:\n",
    "        clean_review_df.append(preprocessing(review,okt, remove_stopwords = True, stop_words = stop_words))\n",
    "    else:\n",
    "        clean_review_df.append([]) #str이 아닌 행은 빈칸으로 놔두기\n",
    "clean_review_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "916db2cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 만족도 5, 4 = df1 전처리\n",
    "stop_words = lst\n",
    "clean_review_df1 = []\n",
    "\n",
    "for review in df1['내용']:\n",
    "    # 리뷰가 문자열인 경우만 전처리 진행\n",
    "    if type(review) == str:\n",
    "        clean_review_df1.append(preprocessing(review,okt, remove_stopwords = True, stop_words = stop_words))\n",
    "    else:\n",
    "        clean_review_df1.append([]) #str이 아닌 행은 빈칸으로 놔두기\n",
    "clean_review_df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "173bd4af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 만족도 2, 1 = df2 전처리\n",
    "stop_words = lst\n",
    "clean_review_df2 = []\n",
    "\n",
    "for review in df2['내용']:\n",
    "    # 리뷰가 문자열인 경우만 전처리 진행\n",
    "    if type(review) == str:\n",
    "        clean_review_df2.append(preprocessing(review,okt, remove_stopwords = True, stop_words = stop_words))\n",
    "    else:\n",
    "        clean_review_df2.append([]) #str이 아닌 행은 빈칸으로 놔두기\n",
    "clean_review_df2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a306a2",
   "metadata": {},
   "source": [
    "# 긍정/부정 단어 빈도 시각화"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab32f62",
   "metadata": {},
   "source": [
    "## 민수님 파일: 만족도로 분류한 긍정과 부정 그룹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3434dbab",
   "metadata": {},
   "outputs": [],
   "source": [
    "high_data=clean_review_df1\n",
    "low_data=clean_review_df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "643af6f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#한 리스트로 결합\n",
    "def list_smaller(l):\n",
    "    oneline=[]\n",
    "    for data in l:\n",
    "        oneline+=data\n",
    "    return oneline\n",
    "high=list_smaller(high_data)\n",
    "low=list_smaller(low_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41885486",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "counter=Counter(high)\n",
    "high_counter=pd.DataFrame.from_dict(data=dict(counter),orient='index')\n",
    "high_counter.reset_index(inplace=True)\n",
    "high_counter.columns = ['단어','갯수']\n",
    "\n",
    "counter=Counter(low)\n",
    "low_counter=pd.DataFrame.from_dict(data=dict(counter),orient='index')\n",
    "low_counter.reset_index(inplace=True)\n",
    "low_counter.columns = ['단어','갯수']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d8a5799",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 갯수 많은 순서대로 확인\n",
    "# high_counter.sort_values('갯수',ascending=False) \n",
    "# low_counter.sort_values('갯수',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "959ce9fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#불용어 사전(부정,긍정 그룹 중 공통 단어 삭제)\n",
    "low_word=list(low_counter['단어'])\n",
    "high_word=list(high_counter['단어'])\n",
    "\n",
    "# 같은 문자 제거\n",
    "def del_common_word(counter,word):\n",
    "    handle=counter['단어'].apply(lambda x: True if x in word else False) #같은 단어면 True\n",
    "    counter_comm=counter[handle]# 같은 문자가 어떤 것인지 마스킹 됨\n",
    "    \n",
    "    print(counter_comm[counter_comm['갯수']>5])# 출력-삭제 대상\n",
    "    common=list(counter_comm[counter_comm['갯수']>5]['단어'])# high에서 없애야할 대상(조건: 5번 이상 반복 출현)\n",
    "    return counter[counter['단어'].apply(lambda x: False if x in common else True)] #제거된 상황\n",
    "high_counter_diff= del_common_word(high_counter,low_word)\n",
    "low_counter_diff=del_common_word(low_counter,high_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c12a4d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "low_counter_diff.sort_values('갯수',ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e6dfe6",
   "metadata": {},
   "source": [
    "### 긍정적(점수 높음)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb1adf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "high_counter_diff_dict=high_counter_diff.set_index('단어').to_dict()\n",
    "high_review=high_counter_diff_dict['갯수']\n",
    "high_review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c5876d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 한글 폰트 설정(.ttf파일 다운로드 후 실행)\n",
    "wordcloud_high = WordCloud('C:\\Windows\\Fonts'+'\\malgun.ttf',max_words=50).generate_from_frequencies(high_review)\n",
    "plt.imshow(wordcloud_high, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f02139c2",
   "metadata": {},
   "source": [
    "## 부정적(점수 낮음)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50398f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "low_counter_diff_dict=low_counter_diff.set_index('단어').to_dict()\n",
    "low_review=low_counter_diff_dict['갯수']\n",
    "low_review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33399887",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 한글 폰트 설정(.ttf파일 다운로드 후 실행)\n",
    "wordcloud_low = WordCloud('C:\\Windows\\Fonts'+'\\malgun.ttf',max_words=50).generate_from_frequencies(low_review)\n",
    "plt.imshow(wordcloud_low, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a2ff3ce",
   "metadata": {},
   "source": [
    "## 파이"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a3e0a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파이 출력을 위해 상위 10개만 파이로 출력\n",
    "for_pie_high=high_counter_diff.sort_values('갯수',ascending=False)[:10]\n",
    "for_pie_low=low_counter_diff.sort_values('갯수',ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ebc693c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dash import Dash, html, dcc, callback, Output, Input\n",
    "import plotly.express as px\n",
    "\n",
    "app = Dash(__name__)\n",
    "\n",
    "high_wordcloud=px.imshow(wordcloud_high)\n",
    "low_wordcloud=px.imshow(wordcloud_low)\n",
    "# high_pie=px.pie(for_pie_high,values='갯수',names='단어')\n",
    "# low_pie=px.pie(for_pie_low,values='갯수',names='단어')\n",
    "high_graph=px.bar(for_pie_high,y='갯수',x='단어')\n",
    "low_graph=px.bar(for_pie_low,y='갯수',x='단어')\n",
    "\n",
    "\n",
    "app.layout = html.Div([\n",
    "    html.Div([\n",
    "        html.H1(children='긍정_워드클라우드', style={'textAlign':'center'}),\n",
    "        dcc.Graph(figure=high_wordcloud),\n",
    "    ],style={'width': '600px', 'height':'600px','margin': '0px 50px 50px 50px','display':'inline-block'}),\n",
    "    html.Div([\n",
    "        html.H1(children='부정_워드클라우드', style={'textAlign':'center'}),\n",
    "        dcc.Graph(figure=low_wordcloud),\n",
    "    ],style={'width': '600px', 'height':'600px','margin': '0px 50px 50px 50px','display':'inline-block'}),\n",
    "    html.Div([\n",
    "        html.H1(children='긍정 상위 10개', style={'textAlign':'center'}),\n",
    "        dcc.Graph(figure=high_graph),\n",
    "    ],style={'width': '600px', 'height':'600px','margin': '0px 50px 50px 50px','display':'inline-block'}),\n",
    "    html.Div([\n",
    "        html.H1(children='부정 상위 10개', style={'textAlign':'center'}),\n",
    "        dcc.Graph(figure=low_graph),\n",
    "    ],style={'width': '600px', 'height':'600px','margin': '0px 50px 50px 50px','display':'inline-block'})\n",
    "],style={'width': '2000px'})\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59a0c549",
   "metadata": {},
   "source": [
    "## 지수님 파일: 감성사전으로 분류한 긍정과 부정 그룹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c814214",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17db0a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전처리\n",
    "df3['sentiment'].unique() #문제 없음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "245de767",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_con=df3['sentiment']>=0\n",
    "positive=df3[positive_con] #긍정 그룹\n",
    "negative=df3[-positive_con] #부정 그룹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de9e5283",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unify(li):\n",
    "    divided=[]\n",
    "    for l in li:\n",
    "        divided.append(l.split())\n",
    "    return divided\n",
    "positive_li=unify(list(positive['review']))\n",
    "negative_li=unify(list(negative['review']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d4c61dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#한 리스트로 결합\n",
    "def list_smaller(l):\n",
    "    oneline=[]\n",
    "    for data in l:\n",
    "        oneline+=data\n",
    "    return oneline\n",
    "posi_l=list_smaller(positive_li)\n",
    "nega_l=list_smaller(negative_li)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f49f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "#불용어 사전 \n",
    "new_posi=[]\n",
    "for l in posi_l:\n",
    "    if l in lst: #korean stopword 삭제\n",
    "        pass\n",
    "    elif re.search('[^가-힣ㄱ-ㅎㅏ-ㅣ\\\\s]',l): # 한글이 아닌 내용 삭제\n",
    "        pass\n",
    "    else:\n",
    "        new_posi.append(l) # 남은 내용만 모으기\n",
    "new_posi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b29015",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_nega=[]\n",
    "for l in nega_l:\n",
    "    if l in lst: #korean stopword 삭제\n",
    "        pass\n",
    "    elif re.search('[^가-힣ㄱ-ㅎㅏ-ㅣ\\\\s]',l): # 한글이 아닌 내용 삭제\n",
    "        pass\n",
    "    else:\n",
    "        new_nega.append(l) # 남은 내용만 모으기\n",
    "new_nega"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d6447c",
   "metadata": {},
   "outputs": [],
   "source": [
    "high=new_posi\n",
    "low=new_nega"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b8fa24",
   "metadata": {},
   "source": [
    "## 반복"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6fa15bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "counter=Counter(high)\n",
    "high_counter=pd.DataFrame.from_dict(data=dict(counter),orient='index')\n",
    "high_counter.reset_index(inplace=True)\n",
    "high_counter.columns = ['단어','갯수']\n",
    "\n",
    "counter=Counter(low)\n",
    "low_counter=pd.DataFrame.from_dict(data=dict(counter),orient='index')\n",
    "low_counter.reset_index(inplace=True)\n",
    "low_counter.columns = ['단어','갯수']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9741a3a9",
   "metadata": {},
   "source": [
    "### 긍정적(감성사전분류)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17989199",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 한글 폰트 설정(.ttf파일 다운로드 후 실행)\n",
    "wordcloud_high = WordCloud('C:\\Windows\\Fonts'+'\\malgun.ttf',max_words=50).generate_from_frequencies(high_review)\n",
    "plt.imshow(wordcloud_high, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b097fc6a",
   "metadata": {},
   "source": [
    "## 부정적(감성사전 분류)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "382707ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "low_counter_diff_dict=low_counter_diff.set_index('단어').to_dict()\n",
    "low_review=low_counter_diff_dict['갯수']\n",
    "low_review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5cba85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 한글 폰트 설정(.ttf파일 다운로드 후 실행)\n",
    "wordcloud_low = WordCloud('C:\\Windows\\Fonts'+'\\malgun.ttf',max_words=50).generate_from_frequencies(low_review)\n",
    "plt.imshow(wordcloud_low, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f06bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파이 출력을 위해 상위 10개만 파이로 출력\n",
    "for_pie_high=high_counter_diff.sort_values('갯수',ascending=False)[:10]\n",
    "for_pie_low=low_counter_diff.sort_values('갯수',ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e797690",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dash import Dash, html, dcc, callback, Output, Input\n",
    "import plotly.express as px\n",
    "\n",
    "app = Dash(__name__)\n",
    "\n",
    "high_wordcloud=px.imshow(wordcloud_high)\n",
    "low_wordcloud=px.imshow(wordcloud_low)\n",
    "# high_pie=px.pie(for_pie_high,values='갯수',names='단어')\n",
    "# low_pie=px.pie(for_pie_low,values='갯수',names='단어')\n",
    "high_graph=px.bar(for_pie_high,y='갯수',x='단어')\n",
    "low_graph=px.bar(for_pie_low,y='갯수',x='단어')\n",
    "\n",
    "\n",
    "app.layout = html.Div([\n",
    "    html.Div([\n",
    "        html.H1(children='긍정_워드클라우드', style={'textAlign':'center'}),\n",
    "        dcc.Graph(figure=high_wordcloud),\n",
    "    ],style={'width': '600px', 'height':'600px','margin': '0px 50px 50px 50px','display':'inline-block'}),\n",
    "    html.Div([\n",
    "        html.H1(children='부정_워드클라우드', style={'textAlign':'center'}),\n",
    "        dcc.Graph(figure=low_wordcloud),\n",
    "    ],style={'width': '600px', 'height':'600px','margin': '0px 50px 50px 50px','display':'inline-block'}),\n",
    "    html.Div([\n",
    "        html.H1(children='긍정 상위 10개', style={'textAlign':'center'}),\n",
    "        dcc.Graph(figure=high_graph),\n",
    "    ],style={'width': '600px', 'height':'600px','margin': '0px 50px 50px 50px','display':'inline-block'}),\n",
    "    html.Div([\n",
    "        html.H1(children='부정 상위 10개', style={'textAlign':'center'}),\n",
    "        dcc.Graph(figure=low_graph),\n",
    "    ],style={'width': '600px', 'height':'600px','margin': '0px 50px 50px 50px','display':'inline-block'})\n",
    "],style={'width': '2000px'})\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3544bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "high_counter_diff.sort_values('갯수',ascending=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb507613",
   "metadata": {},
   "outputs": [],
   "source": [
    "low_counter_diff.sort_values('갯수',ascending=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2abc05ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
