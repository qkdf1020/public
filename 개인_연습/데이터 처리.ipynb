{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 시작"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시작할 때 사용할 패키지\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "import koreanize_matplotlib # 한글 폰트 안 깨지고 사용 가능\n",
    "\n",
    "# 시각화\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "\n",
    "from scipy import stats\n",
    "from statannot import add_stat_annotation\n",
    "\n",
    "# 그래프 한글 표시 요류 관련 해결 방법\n",
    "plt.rc('font', family = 'Malgun Gothic')\n",
    "\n",
    "# 그래프 사이즈 지정\n",
    "plt.rcParams['figure.figsize'] = [12, 8]\n",
    "\n",
    "# 그래프 타이틀 한글 출력\n",
    "plt.rcParams['font.family'] = 'Malgun Gothic'\n",
    "\n",
    "# 없는거 설치\n",
    "# pip install '설치할거'\n",
    "\n",
    "# 경고 표시 제거\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://matplotlib.org/stable/gallery/index.html\n",
    "# https://seaborn.pydata.org/examples/index.html\n",
    "# https://plotly.com/python/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list이름.append('a') # 끝에 추가 a 추가\n",
    "list이름.extend(['a', 'b', 'c']) # 리스트 확장\n",
    "list이름.insert(0, 'b') # 0 위치에 b 추가\n",
    "list이름.count('a') # 리스트에 a 개수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 연산자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# + : A+B 합\n",
    "# - : A-B차\n",
    "# * : 곱\n",
    "# ** : 제곱\n",
    "# / : 나누기\n",
    "# // : 나누기의 몫\n",
    "# % : 나누기의 나머지\n",
    "# > : 크다\n",
    "# < : 작다\n",
    "# >= : 이상\n",
    "# <= : 이하\n",
    "# == : 같은 값\n",
    "# != : 다른 값\n",
    "# = : 할당\n",
    "# := : A할당하고 B를 반환 한다.\n",
    "# [0:1] 슬라이싱 : N : (M-1)까지 범위를 탐색\n",
    "# [0] 인덱싱 : N번쨰 자리를 탐색"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 넘파이"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.repeat(a[0], 0) # a의 [0]자리를 0번 복사한다\n",
    "np.array() # 넘파이 배열로 변환\n",
    "np.append() # 넘파이 배열 이어 붙이기\n",
    "np.shape() # 배열 확인 (0, 0)\n",
    "x.reshape(2, 3) # x를 (2, 3) 2차원으로 바꾼 배열을 리턴\n",
    "([[0, 0, 0],\n",
    "  [0, 0, 0]])\n",
    "x.reshape(2, 2, 3) # x를 (2, 3, 4) 3차원으로 바꾼 배열을 리턴\n",
    "([[0, 0, 0, 0],\n",
    "  [0, 0, 0, 0],\n",
    "  [0, 0, 0, 0]],\n",
    " \n",
    " [[0, 0, 0, 0],\n",
    "  [0, 0, 0, 0],\n",
    "  [0, 0, 0, 0]])\n",
    "np.reshape(x, (2, 2, 3)) # x를 (2, 3, 4) 3차원으로 바꾼 배열을 리턴\n",
    "([[0, 0, 0, 0],\n",
    "  [0, 0, 0, 0],\n",
    "  [0, 0, 0, 0]],\n",
    " \n",
    " [[0, 0, 0, 0],\n",
    "  [0, 0, 0, 0],\n",
    "  [0, 0, 0, 0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 판다스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 경로 확인 및 데이터 프레임 불러오기, 내보내기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OS 모듈\n",
    "os.getcwd() # 현재 프로세스의 작업 디렉토리 확인\n",
    "os.path.exists('경로/확인힐이름') # 경로에 특정 파일이나 디렉토리의 존재 여부 확인\n",
    "os.mkdir('경로' + '/디렉토리명') # 경로에 디렉토리를 생성\n",
    "os.listdir('경로' + '/디렉토리명') # 지정된 경로의 디렉토리에 존재하는 파일 혹인 디렉토리 반환(리스트 형태)\n",
    "os.walk() # 지정된 경로의 디렉토리를 순차적으로 탐색하여 반복문으로 활용\n",
    "os.rename('경로/경로/원래 이름', '경로/경로/바꿀 이름') # 지정한 파일의 이름을 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 지정 경로의 디렉토리를 순차적으로 탐색 -> 주로 for문과 활용\n",
    "check_dir = '경로'\n",
    "for curDir, dirs, files in os.walk(check_dir):\n",
    "    print(curDir, dirs, files)\n",
    "    for f in files :\n",
    "        print(os.path.join(curDir, f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cur_dir_1() -> None:\n",
    "    \"\"\"\n",
    "    Input\n",
    "        1) None\n",
    "    Print\n",
    "        1) 현재 작업 디렉토리\n",
    "        2) 현재 디렉토리 내의 파일과 하위 디렉토리 목록 리스트\n",
    "    Output\n",
    "        1) dir_list (list) :\n",
    "            현재 디렉토리 내의 파일과 하위 디렉토리 목록 리스트\n",
    "    \"\"\"\n",
    "    # 현재 작업 디렉토리 확인\n",
    "    cur_directory = os.getcwd()\n",
    "    print('\\n현재 작업 디렉토리 :\\n', cur_directory)\n",
    "    \n",
    "    # 현재 디렉토리 내의 파일과 하위 디렉토리 목록 -> 리스트로 반환\n",
    "    dir_list = os.listdir(cur_directory)\n",
    "    print('\\n현재 디렉토리 내의 파일과 하위 디렉토리 목록 :\\n', dir_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cur_dir_2(directory_name : str):\n",
    "    \"\"\"\n",
    "    Input\n",
    "        1) directory_name (str) :\n",
    "            현재 작업 디렉토리에서 확인하고 싶은 디렉토리 이름\n",
    "    Print\n",
    "        1) directory_name (str) 내의 파일과 하위 디렉토리 목록 리스트\n",
    "    \"\"\"\n",
    "    # 현재 디렉토리에서 특정 디렉토리 내의 파일과 하위 디렉토리 목록 -> 리스트로 반환\n",
    "    dir_listdir = os.path.join(os.getcwd(), directory_name)\n",
    "    data_list = os.listdir(dir_listdir)\n",
    "    print(f'\\n{dir_listdir} 내의 파일과 하위 디렉토리 목록 :\\n', data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dir_csv_excel(directory_name : str, index_col : int | str = None, encoding : str = None):\n",
    "    \"\"\"\n",
    "    Input\n",
    "        1) directory_name (str) :\n",
    "            현재 작업 디렉토리에서 cvs, excel 파일들을 불러올 디렉토리 이름\n",
    "        2) index_col (int | str) = None :\n",
    "            인덱스로 사용할 열의 번호 또는 이름을 지정\n",
    "        3) encoding (str) = None :\n",
    "            파일의 인코딩을 지정\n",
    "            한글 파일 에러 : 'cp949'\n",
    "            아스키 코드 에러 : 'ISO-8859-1'\n",
    "    Output\n",
    "        1) dataset (dict) :\n",
    "            directory_name (str) 내의 csv, excel 파일,\n",
    "            변수 = dir_csv_excel('directory_name')['파일이름.확장자']로 사용\n",
    "    \"\"\"\n",
    "    # 현재 디렉토리에서 특정 디렉토리 내의 파일과 하위 디렉토리 목록 -> 리스트로 반환\n",
    "    dir_listdir = os.path.join(os.getcwd(), directory_name)\n",
    "    data_list = os.listdir(dir_listdir)\n",
    "    print(f\"\\n'{dir_listdir}' 내의 파일과 하위 디렉토리 목록 :\\n\", data_list)\n",
    "\n",
    "    # csv 파일 대량 불러오기 -> dict 형태로 반환\n",
    "    dataset = dict()\n",
    "    \n",
    "    try:\n",
    "        for data in data_list:\n",
    "            if data.lower().endswith('.csv'): # csv 파일만\n",
    "                print(data) # csv 파일들 출력\n",
    "                dataset[data] = pd.read_csv(os.path.join(dir_listdir, data), index_col = index_col, encoding = encoding)\n",
    "            elif data.lower().endswith('.xls') or data.lower().endswith('.xlsx'):\n",
    "                print('/n', data) # excel 파일들 출력\n",
    "                dataset[data] = pd.read_excel(os.path.join(dir_listdir, data), index_col = index_col)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cur_dir() -> None:\n",
    "    \"\"\"\n",
    "    Input\n",
    "        1) None\n",
    "    Print\n",
    "        1) 현재 작업 디렉토리\n",
    "        2) 현재 디렉토리 내의 파일과 하위 디렉토리 목록 리스트\n",
    "    Output\n",
    "        1) dir_list (list) :\n",
    "            현재 디렉토리 내의 파일과 하위 디렉토리 목록 리스트\n",
    "    \"\"\"\n",
    "    # 현재 작업 디렉토리 확인\n",
    "    cur_directory = os.getcwd()\n",
    "    print('\\n현재 작업 디렉토리 :\\n', cur_directory)\n",
    "    \n",
    "    # 현재 디렉토리 내의 파일과 하위 디렉토리 목록 -> 리스트로 반환\n",
    "    dir_list = os.listdir(cur_directory)\n",
    "    print('\\n현재 디렉토리 내의 파일과 하위 디렉토리 목록 :\\n', dir_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_csv(directory_name : str, index_col : int | str = None, encoding : str = None):\n",
    "    \"\"\"\n",
    "    Input\n",
    "        1) directory_name (str) :\n",
    "            현재 작업 디렉토리에서 cvs 파일들을 불러올 디렉토리 이름\n",
    "        2) index_col (int | str) :\n",
    "            인덱스로 사용할 열의 번호 또는 이름을 지정\n",
    "        3) encoding (str) :\n",
    "            파일의 인코딩을 지정\n",
    "    Print\n",
    "        1) directory_name (str) 내의 파일과 하위 디렉토리 목록 리스트\n",
    "    Output\n",
    "        1) dataset (dict) :\n",
    "            directory_name (str) 내의 csv 파일,\n",
    "            변수 = dataset_csv('directory_name')['csv_파일이름']으로 사용\n",
    "    \"\"\"\n",
    "    # 현재 디렉토리에서 특정 디렉토리 내의 파일과 하위 디렉토리 목록 -> 리스트로 반환\n",
    "    dir_listdir = os.path.join(os.getcwd(), directory_name)\n",
    "    data_list = os.listdir(dir_listdir)\n",
    "    print(f'\\n{dir_listdir} 내의 파일과 하위 디렉토리 목록 :\\n', data_list)\n",
    "\n",
    "    # csv 파일 대량 불러오기 -> dict 형태로 반환\n",
    "    dataset = dict()\n",
    "    \n",
    "    for data in data_list :\n",
    "        print(data[0 : -4]) # 파일 이름에서 확장자 제외\n",
    "        dataset[data[0 : -4]] = pd.read_csv(os.path.join(dir_listdir, data), index_col = index_col, encoding = encoding)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dir_excel(directory_name : str, index_col : int | str = None):\n",
    "    \"\"\"\n",
    "    Input\n",
    "        1) directory_name (str) :\n",
    "            현재 작업 디렉토리에서 excel 파일들을 불러올 디렉토리 이름\n",
    "        2) index_col (int | str) :\n",
    "            인덱스로 사용할 열의 번호 또는 이름을 지정\n",
    "        3) encoding (str) :\n",
    "            파일의 인코딩을 지정\n",
    "    Print\n",
    "        1) directory_name (str) 내의 파일과 하위 디렉토리 목록 리스트\n",
    "    Output\n",
    "        1) dataset (dict) :\n",
    "            directory_name (str) 내의 csv 파일,\n",
    "            변수 = dataset_csv('directory_name')['excel_파일이름']으로 사용\n",
    "    \"\"\"\n",
    "    # 현재 디렉토리에서 특정 디렉토리 내의 파일과 하위 디렉토리 목록 -> 리스트로 반환\n",
    "    dir_listdir = os.path.join(os.getcwd(), directory_name)\n",
    "    data_list = os.listdir(dir_listdir)\n",
    "    print(f'\\n{dir_listdir} 내의 파일과 하위 디렉토리 목록 :\\n', data_list)\n",
    "\n",
    "    # csv 파일 대량 불러오기 -> dict 형태로 반환\n",
    "    dataset = dict()\n",
    "\n",
    "    for data in data_list :\n",
    "        print(data[0 : -5]) # 파일 이름에서 확장자 제외\n",
    "        dataset[data[0: -5]] = pd.read_excel(os.path.join(dir_listdir, data), index_col=index_col)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파일 불러오기를 위한 함수\n",
    "raw_data = pd.read_csv('경로/파일이름.csv', index_col = 0) : csv 파일\n",
    "raw_data = pd.read_csv('경로/파일이름.tsv', sep = '\\t') : tsv 파일\n",
    "raw_data = pd.read_excel('경로/파일이름.xlsx', index_col = 0) : 엑셀 파일\n",
    "\n",
    "# 불러오기 한글 파일 에러\n",
    ", encoding = 'cp949'\n",
    "\n",
    "# 불러오기 아스키 코드 에러\n",
    ", encoding = 'ISO-8859-1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파일 내보내기를 위한 함수\n",
    "df이름.to_csv('filename.csv') # CSV 파일\n",
    "df이름.to_csv('filename.csv', index = False) # CSV 파일\n",
    "df이름.to_csv('filename.tsv') # tsv 파일\n",
    "df이름.to_csv('filename.tsv', sep='\\t') # tsv 파일\n",
    "df이름.to_excel('filename.xlsx') # 엑셀 파일\n",
    "df이름.to_excel('filename.xlsx', index = False) # 엑셀 파일"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 데이터 프레임 합치기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 중복제거 후 인덱스 리셋 후 기존 인덱스 칼럼 삭제\n",
    "df이름.drop_duplicates().reset_index().drop(columns = 'index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# axis = 0 : 행 방향, axis = 1 : 열 방향\n",
    "# join = 'outer' : 합집합, join = 'inner' : 교집합\n",
    "# ignore_index = True : 인덱스 번호 재배열\n",
    "concat_data = pd.concat([raw_data1, raw_data2], ignore_index = True)\n",
    "concat_data = pd.concat([raw_data1, raw_data2], axis = 1, join = 'inner',\n",
    "                        ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how  = 'inner' : 교집합, how = 'outer' : 합집합'\n",
    "# how  = 'left' : 왼쪽, how = 'right' : 오른쪽'\n",
    "# left_on = '왼쪽 칼럼', right_on = '오른쪽 칼럼'\n",
    "merge_data = raw_data1.merge(raw_data2, how = 'inner', on = '칼럼')\n",
    "merge_data = pd.merge(raw_data1, raw_data2) # how = 'inner', on = 공통 열이름 \n",
    "merge_data = pd.merge(raw_data1,raw_data2, how = 'outer',\n",
    "                      left_on = ['칼럼'], right_on = ['칼럼'])\n",
    "merge_data = pd.merge(raw_data1, raw_data2, how = 'left',\n",
    "                      left_on = ['칼럼'], right_on = ['칼럼'])\n",
    "merge_data = pd.merge(raw_data1, raw_data2, how = 'right',\n",
    "                      left_on = ['칼럼'], right_on = ['칼럼'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 데이터 프레임 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_df(df):\n",
    "    \"\"\"\n",
    "    Input\n",
    "        1) df (DataFrame) :\n",
    "            확인하고 싶은 데이터 프레임\n",
    "    Print\n",
    "        1) df (DataFrame)의 rows x columns\n",
    "    display\n",
    "        1) df (DataFrame)의 칼럼별(column)\n",
    "        유니크의 개수(unique_cut), 비결측치의 개수(non_null_cut), 데이터 타입(dtype),\n",
    "        결측치의 개수(null_cut), 결측치의 비율(null_ratio)\n",
    "        2) df (DataFrame)의 칼럼중, 데이터 타입이 수치형인 칼럼들의 describe()\n",
    "        데이터의 총 개수, 평균, 표준 편차, 최솟값, 25, 50, 75 백분위수, 최댓값\n",
    "    \"\"\"\n",
    "    print('rows x columns :', df.shape) # (행 개수, 열 개수)\n",
    "    # 칼럼별 unique 개수 확인\n",
    "    columns_info = dict()\n",
    "    columns = df.columns\n",
    "    for col in columns:\n",
    "        columns_info[col] = len(df[col].unique())\n",
    "    data = [{'index': col, 'unique_cut': count} for col, count in columns_info.items()]\n",
    "    unique_cut_df = pd.DataFrame(data)\n",
    "    # unique_cut_df.set_index('index').T\n",
    "    non_null_cut_df = pd.DataFrame(df.count()).rename(columns = {0 : 'non_null_cut'}).reset_index()# 칼럼별 비결측치 개수\n",
    "    info_df = pd.DataFrame(df.dtypes).rename(columns = {0 : 'dtype'}).reset_index() # 데이터 프레임 info\n",
    "    # 칼럼별 결측지 비율 확인\n",
    "    null_cnt_df = pd.DataFrame(df.isnull().sum()).rename(columns = {0 : 'null_cut'}).reset_index()\n",
    "    null_cnt_df['null_ratio'] = round(null_cnt_df['null_cut'] / len(df) * 100, 2)\n",
    "    # 합치기\n",
    "    unique_non_null_cut_df = pd.merge(unique_cut_df, non_null_cut_df)\n",
    "    unique_non_null_info_cut_df = pd.merge(unique_non_null_cut_df, info_df)\n",
    "    unique_non_null_info_null_cut_df = pd.merge(unique_non_null_info_cut_df, null_cnt_df).rename(columns = {'index' : 'column'})\n",
    "    # describe - 통계\n",
    "    int_float_cnt  = unique_non_null_info_null_cut_df[(unique_non_null_info_null_cut_df['dtype'] == 'int64') |\n",
    "                     (unique_non_null_info_null_cut_df['dtype'] == 'float64')]\n",
    "    # 보여주기\n",
    "    if len(unique_non_null_info_null_cut_df.columns) >= len(int_float_cnt.columns):\n",
    "        len_number = len(unique_non_null_info_null_cut_df.columns)\n",
    "    else:\n",
    "        len_number = len(int_float_cnt.columns)\n",
    "    pd.set_option('display.max_columns', len_number)            \n",
    "    display(unique_non_null_info_null_cut_df)\n",
    "    display(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테이블 칼럼 타입 확인\n",
    "df이름.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테이블 수치형 칼럼 통계\n",
    "df이름.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_df = df이름\n",
    "print('칼럼명 :', df_check.columns) # 칼럼명 확인\n",
    "print('(rows, columns) :', df_check.shape) # (행 개수, 열 개수)\n",
    "df_check.count() # 칼럼별 항목 개수 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 칼럼 unique별 개수 확인\n",
    "df이름['칼럼명'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 머리와 꼬리 동시에 보기\n",
    "display_df = df이름\n",
    "display(display_df.head(3))\n",
    "display(display_df.tail(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 두개의 데이터 머리만 동시에 보기\n",
    "display(df이름.head(3), df이름.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 해당 수의 행, 열 만큼 보이게 하기\n",
    "pd.set_option('display.max_rows', 숫자)\n",
    "pd.set_option('display.max_columns', len(df이름.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 칼럼별 unique 개수 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 칼럼별 unique 개수 확인\n",
    "unique_check_df = df이름\n",
    "\n",
    "columns_info = dict()\n",
    "columns = unique_check_df.columns\n",
    "for col in columns:\n",
    "    columns_info[col] = len(unique_check_df[col].unique())\n",
    "\n",
    "columns_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 칼럼별 unique 개수 확인\n",
    "unique_check_df = df이름\n",
    "\n",
    "columns_info = dict()\n",
    "columns = check_df.columns\n",
    "for col in columns:\n",
    "    columns_info[col] = len(check_df[col].unique())\n",
    "data = [{'columns': col, 'unique_count': count} for col, count in columns_info.items()]\n",
    "unique_count_df = pd.DataFrame(data)\n",
    "unique_count_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 칼럼 타입 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 칼럼 타입 변경\n",
    "df이름 = df이름.astype({'칼럼명' : 'object', \n",
    "                    '칼럼명' : 'int64',\n",
    "                    '칼럼명' : 'float64',\n",
    "                    '칼럼명' : 'bool',\n",
    "                    '칼럼명' : 'datetime64[ns]'})\n",
    "df이름.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 칼럼 값(values) 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 칼럼 값(values) 변경\n",
    "def change_value(values) :\n",
    "    if values == '기존' :\n",
    "        return '변경'\n",
    "    elif values == '기존' :\n",
    "        return '변경'\n",
    "\n",
    "df이름['칼럼명'] = df이름['칼럼명'].apply(change_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df이름['칼럼명'] = df이름['칼럼명'].map({'기존' : '변경', '기존' : '변경'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 띄어쓰기 기준으로 칼럼 내용 내눠서 각 칼럼으로 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 띄어쓰기 기준으로 칼럼 내용 내눠서 각 칼럼으로 저장\n",
    "df이름['새칼럼명'] = df이름['기존칼럼명'].apply(\n",
    "    lambda x: x.split(' ')[0][ : ])\n",
    "\n",
    "df이름['새칼럼명'] = df이름['기존칼럼명'].apply(\n",
    "    lambda x: x.split(' ')[1][ : ])\n",
    "\n",
    "pd.set_option('display.max_columns', len(df이름.columns))\n",
    "df이름.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 칼럼명 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단일 칼럼명 변경\n",
    "df이름 = df이름.rename(columns = {'칼럼명' : '변경명'})\n",
    "\n",
    "# 복수 칼럼명 변경\n",
    "df이름 = df이름.rename(columns = {'칼럼명' : '변경명',\n",
    "                              '칼럼명' : '변경명',\n",
    "                              '칼럼명' : '변경명',\n",
    "                              '칼럼명' : '변경명',\n",
    "                              '칼럼명' : '변경명',\n",
    "                              '칼럼명' : '변경명',\n",
    "                              '칼럼명' : '변경명',\n",
    "                              '칼럼명' : '변경명',\n",
    "                              '칼럼명' : '변경명',\n",
    "                              '칼럼명' : '변경명',\n",
    "                              '칼럼명' : '변경명',\n",
    "                              '칼럼명' : '변경명'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 칼럼명 지정 문자 바꾸기\n",
    "df이름 = df이름.columns.str.replace('기존_문자', '바꿀_문자')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 칼럼명 지정 문자 추가\n",
    "df이름.add_prefix('추가_문자') # 칼럼명 앞에 추가\n",
    "df이름.add_suffix('추가_문자') # 칼럼명 뒤에 추가"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 행, 열의 순서 변경, 삽입, 삭제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 칼럼 순서 변경\n",
    "df이름 = df이름[['칼럼명', '칼럼명', ..., '칼럼명']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 칼럼 삽입 ==, >, <, !=\n",
    "df이름['새칼럼명'] = 값\n",
    "df이름['새칼럼명'] = df이름['기존칼럼명'] + df이름['기존칼럼명']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단일 칼럼 삭제\n",
    "df이름 = df이름.drop(columns = '삭제할칼럼명')\n",
    "df이름 = df이름.drop('삭제할칼럼명', axis = 1)\n",
    "del df이름['삭제할칼럼명']\n",
    "\n",
    "# 복수 칼럼 삭제\n",
    "df이름 = df이름.drop(['삭제할칼럼명', '삭제할칼럼명'], axis = 1)\n",
    "del df이름['삭제할칼럼명'], df이름['삭제할칼럼명']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 중복제거 후 인덱스 리셋 후 기존 인덱스 칼럼 삭제\n",
    "df이름.drop_duplicates().reset_index().drop(columns = 'index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 로우(행) 삭제\n",
    "df이름.drop(index = '인덱스_번호')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df이름 = df이름.sort_values(by = ['칼럼명']) # 오름차순\n",
    "df이름 = df이름.sort_values(by = ['칼럼명'], ascending = False) # 내림차순"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 필터링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필터링 ==, >, <, !=\n",
    "df이름[df이름['칼럼명'] == 값] # 전일치 검색\n",
    "df이름[(df이름['칼럼명'] == 값) & (df이름['칼럼명'] == 값)] # 복합조건\n",
    "df이름[(df이름['칼럼명'] == 값) | (df이름['칼럼명'] == 값)] # 복합조건\n",
    "df이름[df이름['칼럼명'].apply(lambda x : x.startswith(값))] # 머릿말 검색\n",
    "df이름[df이름['칼럼명'].apply(lambda x : x.endswith(값))] # 꼬릿말 검색\n",
    "df이름[df이름['칼럼명'].isin([값, 값, 값])] # 내용을 포함하는지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 내용을 포함하는지\n",
    "target = [값, 값, 값]\n",
    "df이름[df이름['칼럼명'].apply(lambda x : x in target)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 칼럼, 인덱스 목록 리스트로 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 칼럼, 인덱스 목록 리스트로 반환\n",
    "list(df이름.columns) # 칼럼\n",
    "df이름.columns.tolist() # 칼럼\n",
    "list(df이름.columns.values) # 칼럼\n",
    "\n",
    "list(df이름.index) # 인덱스\n",
    "df이름.index.tolist() # 인덱스\n",
    "list(df이름.index.values) # 인덱스"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 모든 열을 행으로 이동시키기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모든 열을 행으로 이동시키기\n",
    "df이름.T\n",
    "pd.melt(df이름, id_vars = ['A'], value_vars = ['B']) # 데이터프레임의 A열은 그대로 두고, B열만 행으로 이동\n",
    "pd.melt(df이름, id_vars = ['A'], value_vars = ['B', 'C']) # A열만 그대로, B열과 C열은 행으로 이동\n",
    "df이름.pivot(index = 'A', columns = 'B', values = 'C') # A열을 새로운 인덱스로 만들고, B열 데이터는 새로운 열로 만들며, C열이 그 안의 데이터가 되도록 설정\n",
    "df이름.reset_index() : 인덱스를 리셋\n",
    "df이름.columns.name = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 피봇 테이블"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 피봇 테이블\n",
    "pd.pivot_table(df이름, index = ['칼럼명', '칼럼명']) # 기본\n",
    "pd.pivot_table(df이름, index = ['칼럼명','칼럼명'],\n",
    "               values = ['칼럼명', '칼럼명'], # 원하는 칼럼\n",
    "               columns = ['거래처'], # 원하는 칼럼\n",
    "               aggfunc = ['산식', '산식'], # 원하는 산식\n",
    "               fill_value = 0, # nan값 0으로\n",
    "               margins = True) # 오른쪽 끝에 총계 추가\n",
    "\n",
    "# 피봇 테이블 필터링\n",
    "pivot_table명.query(\"인덱스명 == ['인덱스값', '인덱스값']\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### groupby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groupby_df이름 = data.groupby(by = '칼럼명')\n",
    "groupby_df이름.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# groupby 하나의 계산\n",
    "# df이름.groupby('그룹칼럼1')['집계칼럼'].집계함수() : A칼럼 그룹의 B칼럼값을 집계함수\n",
    "groupby_df이름 = df이름.groupby('그룹칼럼')['집계칼럼'].mean() # 평균\n",
    "groupby_df이름 = df이름.groupby('그룹칼럼')['집계칼럼'].median() # 중위수\n",
    "groupby_df이름 = df이름.groupby('그룹칼럼')['집계칼럼'].count() # 개수\n",
    "groupby_df이름 = df이름.groupby('그룹칼럼')['집계칼럼'].sum() # 합산\n",
    "groupby_df이름 = df이름.groupby('그룹칼럼')['집계칼럼'].min() # 최소\n",
    "groupby_df이름 = df이름.groupby('그룹칼럼')['집계칼럼'].max() # 최대\n",
    "groupby_df이름 = df이름.groupby('그룹칼럼')['집계칼럼'].std() # 표준편차\n",
    "groupby_df이름 = df이름.groupby('그룹칼럼')['집계칼럼'].var() # 분산\n",
    "groupby_df이름 = df이름.groupby('그룹칼럼')['집계칼럼'].quantile() # 특정 백분위\n",
    "groupby_df이름 = df이름.groupby('그룹칼럼')['집계칼럼'].describe() # 전반적인 지표\n",
    "groupby_df이름 = df이름.groupby(['A칼럼1', 'A칼럼2'])['B칼럼'].집계함수()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groupby_df이름 = pd.DataFrame(df이름.groupby('그룹칼럼1')['집계칼럼'].count()).reset_index()\n",
    "groupby_df이름 = groupby_df이름.rename(columns = {'기존칼럼명' : '바꿀칼럼명', '기존칼럼명' : '바꿀칼럼명'})\n",
    "groupby_df이름"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# groupby 복수의 계산\n",
    "groupby_df이름 = df이름.groupby(['A칼럼1','A칼럼2']).agg(\n",
    "    {'계산할컬럼명1' : 집계함수1(),\n",
    "     '계산할컬럼명2' : 집계함수2(),\n",
    "     '계산할컬럼명3' : 집계함수3()}\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# groupby 복수의 계산\n",
    "groupby_df이름 = pd.DataFrame(\n",
    "    {'새로운컬럼명1' : df이름.groupby(['A칼럼1','A칼럼2'])['집계칼럼'].집계함수1(),\n",
    "     '새로운컬럼명2' : df이름.groupby(['A칼럼1','A칼럼2'])['집계칼럼'].집계함수2(),\n",
    "     '새로운컬럼명3' : df이름.groupby(['A칼럼1','A칼럼2'])['집계칼럼'].집계함수3()}\n",
    "   )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 결측치\n",
    "\n",
    "#####  머신러닝 및 데이터 분석에서 상황과 목적에 맞게 처리해야 하는 중요한 프로세스 중 하나\n",
    "\n",
    "\n",
    "\n",
    "1. 결측치 비율이 10% 미만인 경우\n",
    "- 삭제 가능\n",
    "<p>\n",
    "\n",
    "\n",
    "2. 결측치 비율이 30% ~ 50%인 경우\n",
    "- 삭제 위험\n",
    "<p>\n",
    "\n",
    "\n",
    "3. 결측치 비율이 50% 이상인 경우\n",
    "- 데이터 자체에 대한 추가 검증 필요 or 해당 컬럼의 제거 고려\n",
    "<p> \n",
    "    \n",
    "==============================\n",
    "##### * 결측치를 처리하는 방법은 다양\n",
    "    \n",
    "1. 제거\n",
    "- 한개 이상의 결측치가 있는 모든 행 제거\n",
    "    \n",
    "2. 대치\n",
    "- 결측치를 특정값(평균, 최소, 최대, 최반값 등등)으로 대체\n",
    "    \n",
    "3. 보간법\n",
    "- 추세를 결측치 이외의 값들을 선형적으로 같은 간격으로 처리 (시계열 데이터에 적합)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 칼럼별 결측지 비율 확인\n",
    "null_check_df = df이름\n",
    "null_cnt_df = pd.DataFrame(null_check_df.isnull().sum()).rename(columns = {0 : 'null_count'}).reset_index()\n",
    "null_cnt_df['null_ratio'] = round(null_cnt_df['null_count'] / len(null_check_df) * 100, 2)\n",
    "null_cnt_df = null_cnt_df.rename(columns = {'index' : 'columns'})\n",
    "null_cnt_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def null_cnt(null_check_df):\n",
    "    \"\"\"\n",
    "    Input\n",
    "        1) null_check_df (DataFrame) :\n",
    "            확인하고 싶은 데이터 프레임\n",
    "\n",
    "    Output\n",
    "        1) null_cnt_df (DataFrame)의 칼럼별(column) 결측치의 개수(null_cut)\n",
    "    \"\"\"\n",
    "    null_cnt_df = pd.DataFrame(null_check_df.isnull().sum()).rename(columns = {0 : 'null_count'}).reset_index()\n",
    "    null_cnt_df['null_ratio'] = round(null_cnt_df['null_count'] / len(null_check_df) * 100, 2)\n",
    "    null_cnt_df = null_cnt_df.rename(columns = {'index' : 'columns'})\n",
    "    \n",
    "    return null_cnt_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_df(df):\n",
    "    \"\"\"\n",
    "    Input\n",
    "        1) df (DataFrame) :\n",
    "            확인하고 싶은 데이터 프레임\n",
    "    Print\n",
    "        1) df (DataFrame)의 rows x columns\n",
    "    display\n",
    "        1) df (DataFrame)의 칼럼별(column)\n",
    "        유니크의 개수(unique_cut), 비결측치의 개수(non_null_cut), 데이터 타입(dtype),\n",
    "        결측치의 개수(null_cut), 결측치의 비율(null_ratio)\n",
    "        2) df (DataFrame)의 칼럼중, 데이터 타입이 수치형인 칼럼들의 describe()\n",
    "        데이터의 총 개수, 평균, 표준 편차, 최솟값, 25, 50, 75 백분위수, 최댓값\n",
    "    \"\"\"\n",
    "    print('rows x columns :', df.shape) # (행 개수, 열 개수)\n",
    "    # 칼럼별 unique 개수 확인\n",
    "    columns_info = dict()\n",
    "    columns = df.columns\n",
    "    for col in columns:\n",
    "        columns_info[col] = len(df[col].unique())\n",
    "    data = [{'index': col, 'unique_cut': count} for col, count in columns_info.items()]\n",
    "    unique_cut_df = pd.DataFrame(data)\n",
    "    # unique_cut_df.set_index('index').T\n",
    "    non_null_cut_df = pd.DataFrame(df.count()).rename(columns = {0 : 'non_null_cut'}).reset_index()# 칼럼별 비결측치 개수\n",
    "    info_df = pd.DataFrame(df.dtypes).rename(columns = {0 : 'dtype'}).reset_index() # 데이터 프레임 info\n",
    "    # 칼럼별 결측지 비율 확인\n",
    "    null_cnt_df = pd.DataFrame(df.isnull().sum()).rename(columns = {0 : 'null_cut'}).reset_index()\n",
    "    null_cnt_df['null_ratio'] = round(null_cnt_df['null_cut'] / len(df) * 100, 2)\n",
    "    # 합치기\n",
    "    unique_non_null_cut_df = pd.merge(unique_cut_df, non_null_cut_df)\n",
    "    unique_non_null_info_cut_df = pd.merge(unique_non_null_cut_df, info_df)\n",
    "    unique_non_null_info_null_cut_df = pd.merge(unique_non_null_info_cut_df, null_cnt_df).rename(columns = {'index' : 'column'})\n",
    "    # describe - 통계\n",
    "    int_float_cnt  = unique_non_null_info_null_cut_df[(unique_non_null_info_null_cut_df['dtype'] == 'int64') |\n",
    "                     (unique_non_null_info_null_cut_df['dtype'] == 'float64')]\n",
    "    # 보여주기\n",
    "    if len(unique_non_null_info_null_cut_df.columns) >= len(int_float_cnt.columns):\n",
    "        len_number = len(unique_non_null_info_null_cut_df.columns)\n",
    "    else:\n",
    "        len_number = len(int_float_cnt.columns)\n",
    "    pd.set_option('display.max_columns', len_number)            \n",
    "    display(unique_non_null_info_null_cut_df)\n",
    "    display(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결측치 유무 확인\n",
    "df이름['칼럼명'].isna().unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결측치 처리\n",
    "df이름 = df이름.fillna('A') # 대상 전체의 nan값을 A로 변경\n",
    "df이름 = df이름.fillna(df이름.mean()) # 대상 전체의 nan값을 평균으로 변경\n",
    "df이름 = df이름.dropna(axis = 0, subset = ['칼럼명']) # axis = 0 행방향\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단일 칼럼 삭제\n",
    "df이름 = df이름.drop(columns = '삭제할칼럼명')\n",
    "df이름 = df이름.drop('삭제할칼럼명', axis = 1)\n",
    "del df이름['삭제할칼럼명']\n",
    "\n",
    "# 복수 칼럼 삭제\n",
    "df이름 = df이름.drop(['삭제할칼럼명', '삭제할칼럼명'], axis = 1)\n",
    "del df이름['삭제할칼럼명'], df이름['삭제할칼럼명']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 해당 칼럼의 값과 일치하는 인덱스 번호\n",
    "df이름.index[df이름['칼럼명'] == 값].tolist()[칼럼 순서 위치]\n",
    "\n",
    "# 해당 인덱스 번호와 일치하는 칼럼의 값\n",
    "df이름.loc[인덱스번호].tolist()[칼럼 순서 위치]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
